{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from urllib.parse import urlparse\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "\n",
    "DB_PATH = './teledeck.db'\n",
    "\n",
    "conn = sqlite3.connect(DB_PATH)\n",
    "\n",
    "\n",
    "cursor = conn.cursor()\n",
    "cursor2 = conn.cursor()\n",
    "url_pattern = r'https?://[^\\s]+'\n",
    "\n",
    "def extract_links_and_domains(text):\n",
    "    links = re.findall(url_pattern, text)\n",
    "    domains = [urlparse(link).netloc for link in links]\n",
    "    return links, domains\n",
    "\n",
    "\n",
    "all_links = []\n",
    "all_domains = set()\n",
    "\n",
    "for row in cursor.execute(\"SELECT text FROM media_items where text <> ''\"):\n",
    "    links, domains = extract_links_and_domains(row[0])\n",
    "    if links:\n",
    "        all_links.append(links)\n",
    "        all_domains.update(domains)\n",
    "\n",
    "print(\"\\nUnique domain names:\")\n",
    "for domain in all_domains:\n",
    "    print(domain)\n",
    "\n",
    "\n",
    "json.dump({'links': all_links, 'domains': list(domains)}, open('data/links.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_links = sorted(list(set([link for links in all_links for link in links])))\n",
    "len(flat_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[print(domain) for domain in all_domains]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Treat these separately \"t.co\"\n",
    "\n",
    "import re\n",
    "twitter_alikes = [\n",
    "    \"twitter\",\n",
    "    \"pxtwitter\",\n",
    "    \"vxtwitter\",\n",
    "    \"zztwitter\",\n",
    "    \"fixupx\",\n",
    "    \"vxTwitter\",\n",
    "    \"twxtter\",\n",
    "    \"fixvx\",\n",
    "    \"FXTwitter\"\n",
    "]\n",
    "\n",
    "twitter_alikes_re = '|'.join(twitter_alikes)\n",
    "is_twitter_alike = re.compile(twitter_alikes_re)\n",
    "\n",
    "twitter_links = [link for link in flat_links if is_twitter_alike.search(link.lower())]\n",
    "len(twitter_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_user = re.compile(r'https?://[^/]+/([^/]+)/(.+)$')\n",
    "extract_alternate = re.compile(f'https?://(www\\.)?({twitter_alikes_re})(.com|.co)?/([^/\\)\\.\\?]+)')\n",
    "\n",
    "\n",
    "users = set()\n",
    "for link in twitter_links:\n",
    "    match = extract_user.match(link)\n",
    "    if match:\n",
    "        users.add(match[1])\n",
    "        continue\n",
    "    match = extract_alternate.match(link)\n",
    "    if match:\n",
    "        users.add(match[1])\n",
    "    else:\n",
    "        print(link)\n",
    "\n",
    "\n",
    "users = list(users)\n",
    "print(users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(users, open('data/twitter_users.json', 'w'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
